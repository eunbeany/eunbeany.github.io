---
title: "Project2"
output: html_document
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="r-markdown" class="section level2">
<h2>R Markdown</h2>
<p>This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <a href="http://rmarkdown.rstudio.com" class="uri">http://rmarkdown.rstudio.com</a>.</p>
<p>When you click the <strong>Knit</strong> button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:</p>
</div>
<div id="nam-nguyen-nhn325" class="section level2">
<h2>Nam Nguyen nhn325</h2>
<div id="summary-i-found-the-dataset-on-professor-salaries-from-the-cardata-library.-the-variables-in-this-dataset-are-professors-rank-assistant-professor-associate-professor-and-professor-discipline-atheoretical-bapplied-number-of-years-since-phd-yrs.since.phd-number-of-years-in-service-yrs.service-sex-male-or-female-and-nine-month-salary-u.s.-dollars.-the-data-was-collected-over-a-9-month-period-in-2008-and-2009-in-hopes-of-finding-out-whether-sex-affected-professor-salaries." class="section level5">
<h5>Summary: I found the dataset on Professor Salaries from the carData library. The variables in this dataset are professors’ rank (Assistant Professor, Associate Professor, and Professor), discipline (A=‘Theoretical’, B=‘Applied’), number of years since phd (yrs.since.phd), number of years in service (yrs.service), sex (male or female), and nine month salary (U.S. dollars). The data was collected over a 9 month period in 2008 and 2009 in hopes of finding out whether sex affected professor salaries.</h5>
<hr />
</div>
<div id="load-in-libaries-and-data" class="section level5">
<h5>load in libaries and data</h5>
<pre class="r"><code>library(carData)
library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.4     v dplyr   1.0.2
## v tidyr   1.1.2     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.0</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(dplyr)
library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>library(sandwich)</code></pre>
</div>
<div id="multivariate-analysis-of-variance" class="section level4">
<h4>Multivariate Analysis of Variance</h4>
<pre class="r"><code>manova &lt;- manova(cbind(yrs.since.phd, yrs.service, salary) ~ rank, data = Salaries)
summary(manova)</code></pre>
<pre><code>##            Df  Pillai approx F num Df den Df    Pr(&gt;F)    
## rank        2 0.63281   60.633      6    786 &lt; 2.2e-16 ***
## Residuals 394                                             
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(manova)</code></pre>
<pre><code>##  Response yrs.since.phd :
##              Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## rank          2  32390 16194.8  191.18 &lt; 2.2e-16 ***
## Residuals   394  33376    84.7                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response yrs.service :
##              Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## rank          2  24812   12406   115.9 &lt; 2.2e-16 ***
## Residuals   394  42175     107                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response salary :
##              Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## rank          2 1.4323e+11 7.1616e+10  128.22 &lt; 2.2e-16 ***
## Residuals   394 2.2007e+11 5.5855e+08                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="the-variables-show-a-significance-mean-difference-across-groups-in-the-multivariate-analysis.-we-run-a-univariate-analysis-to-see-if-there-is-a-mean-difference-accross-groups." class="section level5">
<h5>The variables show a significance mean difference across groups in the multivariate analysis. We run a univariate analysis to see if there is a mean difference accross groups.</h5>
</div>
</div>
<div id="univariate-analysis-of-variance" class="section level4">
<h4>Univariate Analysis of Variance</h4>
<pre class="r"><code>anova &lt;- aov(yrs.since.phd ~ rank, data = Salaries)
summary(anova)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
## rank          2  32390   16195   191.2 &lt;2e-16 ***
## Residuals   394  33376      85                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="the-response-variables-all-show-significant-difference" class="section level5">
<h5>The response variables all show significant difference</h5>
<pre class="r"><code>pairwise.t.test(Salaries$yrs.since.phd, Salaries$rank, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Salaries$yrs.since.phd and Salaries$rank 
## 
##           AsstProf AssocProf
## AssocProf 3.6e-10  -        
## Prof      &lt; 2e-16  &lt; 2e-16  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(Salaries$yrs.service, Salaries$rank, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Salaries$yrs.service and Salaries$rank 
## 
##           AsstProf AssocProf
## AssocProf 2.0e-07  -        
## Prof      &lt; 2e-16  3.2e-13  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(Salaries$salary, Salaries$rank, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Salaries$salary and Salaries$rank 
## 
##           AsstProf AssocProf
## AssocProf 0.0016   -        
## Prof      &lt;2e-16   &lt;2e-16   
## 
## P value adjustment method: none</code></pre>
</div>
<div id="we-have-conducted-four-hypothesis-testsone-anova-and-three-post-hoc-t-tests-the-type-i." class="section level5">
<h5>We have conducted four hypothesis tests(one Anova and three post-hoc t tests The Type I).</h5>
</div>
<div id="the-type-i-error-probability-is-1---.954-.1855" class="section level5">
<h5>The Type I error probability is 1 - .95^(4) = .1855</h5>
</div>
<div id="the-bonferroni-correction-alpha-is-.054-.0125" class="section level5">
<h5>The Bonferroni correction alpha is .05/4 = .0125</h5>
</div>
</div>
<div id="bonferroni-adjustment" class="section level4">
<h4>Bonferroni adjustment</h4>
<pre class="r"><code>pairwise.t.test(Salaries$yrs.since.phd, Salaries$rank, p.adj = &quot;bonferroni&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Salaries$yrs.since.phd and Salaries$rank 
## 
##           AsstProf AssocProf
## AssocProf 1.1e-09  -        
## Prof      &lt; 2e-16  &lt; 2e-16  
## 
## P value adjustment method: bonferroni</code></pre>
<pre class="r"><code>pairwise.t.test(Salaries$yrs.service, Salaries$rank, p.adj = &quot;bonferroni&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Salaries$yrs.service and Salaries$rank 
## 
##           AsstProf AssocProf
## AssocProf 5.9e-07  -        
## Prof      &lt; 2e-16  9.7e-13  
## 
## P value adjustment method: bonferroni</code></pre>
<pre class="r"><code>pairwise.t.test(Salaries$salary, Salaries$rank, p.adj = &quot;bonferroni&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  Salaries$salary and Salaries$rank 
## 
##           AsstProf AssocProf
## AssocProf 0.0049   -        
## Prof      &lt;2e-16   &lt;2e-16   
## 
## P value adjustment method: bonferroni</code></pre>
<div id="manova-assumptions-such-as-random-sampling-independent-observations-linear-relationships-among-dependent-variables-and-homogeneity-are-likely-to-have-been-met." class="section level5">
<h5>MANOVA assumptions such as random sampling, independent observations, linear relationships among dependent variables, and homogeneity are likely to have been met.</h5>
</div>
</div>
<div id="mean-difference-randomization-test" class="section level3">
<h3>Mean-difference randomization test</h3>
<pre class="r"><code>rand_dist&lt;-vector()
for(i in 1:5000){
new&lt;-data.frame(yrs_since_phd=sample(Salaries$yrs.since.phd),rank=Salaries$rank)
rand_dist[i]&lt;-mean(new[new$rank==&quot;Prof&quot;,]$yrs_since_phd)-
mean(new[new$rank==&quot;AssocProf&quot;,]$yrs_since_phd)
}</code></pre>
<div id="null-hypothesis-there-is-no-difference-accross-group-means" class="section level5">
<h5>Null Hypothesis: There is no difference accross group means</h5>
</div>
<div id="alternative-hypothesis-there-is-a-difference-accross-group-means" class="section level5">
<h5>Alternative Hypothesis: There is a difference accross group means</h5>
</div>
</div>
<div id="visualization-of-the-mean-difference-randomization-test" class="section level3">
<h3>Visualization of the mean difference randomization test</h3>
<div id="the-graph-shows-a-normal-distribution-and-we-are-able-to-reject-the-null-hypothesis-as-the-p-value-is-less-than-.05" class="section level5">
<h5>The graph shows a normal distribution and we are able to reject the null hypothesis as the p-value is less than .05</h5>
<pre class="r"><code>{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;)}</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>Salaries %&gt;% group_by(rank) %&gt;% summarise(means = mean(yrs.since.phd))</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 3 x 2
##   rank      means
##   &lt;fct&gt;     &lt;dbl&gt;
## 1 AsstProf   5.10
## 2 AssocProf 15.5 
## 3 Prof      28.3</code></pre>
<pre class="r"><code>mean_diff_Prof_AssocProf = 28.3 - 15.453
mean(rand_dist&gt;12.847 | rand_dist &lt; -12.847) #p-value</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
</div>
<div id="linear-regression-model" class="section level3">
<h3>Linear Regression Model</h3>
<pre class="r"><code>fit1&lt;-lm(salary~yrs.since.phd * yrs.service, data=Salaries) 
summary(fit1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = salary ~ yrs.since.phd * yrs.service, data = Salaries)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -63823 -17292  -2538  13158 107001 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               70155.263   3472.077  20.206  &lt; 2e-16 ***
## yrs.since.phd              2194.289    246.862   8.889  &lt; 2e-16 ***
## yrs.service                1692.446    356.279   4.750 2.85e-06 ***
## yrs.since.phd:yrs.service   -64.617      7.487  -8.630  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 25120 on 393 degrees of freedom
## Multiple R-squared:  0.3177, Adjusted R-squared:  0.3125 
## F-statistic: 60.99 on 3 and 393 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>coeftest(fit1)</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)               70155.2627  3472.0772 20.2056 &lt; 2.2e-16 ***
## yrs.since.phd              2194.2887   246.8621  8.8887 &lt; 2.2e-16 ***
## yrs.service                1692.4465   356.2786  4.7503 2.852e-06 ***
## yrs.since.phd:yrs.service   -64.6169     7.4871 -8.6304 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>coef(fit1)</code></pre>
<pre><code>##               (Intercept)             yrs.since.phd               yrs.service 
##               70155.26272                2194.28869                1692.44646 
## yrs.since.phd:yrs.service 
##                 -64.61694</code></pre>
<div id="the-intercept-is-the-predicted-salary-for-an-average-professor-regardless-of-rank-70155.26.-controlling-for-years-of-service-the-years-since-phd-shows-an-increase-of-2194.28-for-every-unit-increase-in-year.-controlling-for-years-since-phd-years-of-service-shows-an-increase-of-1692.44-for-every-unit-increase-in-year.-the-slope-of-the-interaction-is--64.61." class="section level5">
<h5>The intercept is the predicted salary for an average professor regardless of rank ($70,155.26). Controlling for years of service, the years since PhD shows an increase of $2194.28 for every unit increase in year. Controlling for years since PhD, years of service shows an increase of $1692.44 for every unit increase in year. The slope of the interaction is -$64.61.</h5>
</div>
</div>
<div id="mean-centering-the-variables" class="section level3">
<h3>Mean-centering the variables</h3>
<div id="predicting-salary-from-years-since-phd-and-years-of-service-with-interation." class="section level5">
<h5>Predicting salary from years since phd and years of service with interation.</h5>
<pre class="r"><code>x1 &lt;- scale(Salaries$yrs.since.phd)
x2 &lt;- scale(Salaries$yrs.service)
y &lt;- scale(Salaries$salary)</code></pre>
</div>
</div>
<div id="linear-regression-model-plot" class="section level3">
<h3>Linear Regression Model Plot</h3>
<pre class="r"><code>ggplot(data.frame(x1,x2,y), aes(x1,y, color = x2))+geom_point()+geom_smooth(method=&quot;lm&quot;,se=F) + ylab(&#39;Salary&#39;) + xlab(&#39;Years since PhD&#39;)</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="residual-plot" class="section level3">
<h3>Residual plot</h3>
<div id="plot-the-residuals-to-check-whether-linearity-is-met" class="section level5">
<h5>Plot the residuals to check whether linearity is met</h5>
</div>
<div id="the-red-line-on-the-plot-should-be-horizontal" class="section level5">
<h5>The red line on the plot should be horizontal</h5>
<pre class="r"><code>assumptions &lt;- lm(salary ~ yrs.since.phd * yrs.service, data = Salaries)
plot(assumptions, 1)</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
</div>
<div id="qq-plot" class="section level3">
<h3>QQ plot</h3>
<div id="assumption-of-normality-seems-to-be-ok-as-the-plot-resembles-a-straight-line" class="section level5">
<h5>Assumption of normality seems to be OK as the plot resembles a straight line</h5>
<pre class="r"><code>plot(assumptions, 2)</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="scale-location-plot-square-rooted-standardized-residual-vs.-predicted-value" class="section level3">
<h3>Scale-location plot (square rooted standardized residual vs. predicted value)</h3>
<div id="testing-homoscedasticity" class="section level5">
<h5>Testing homoscedasticity</h5>
</div>
<div id="the-red-line-should-be-flat-and-the-points-should-be-equally-spread-out" class="section level5">
<h5>The red line should be flat and the points should be equally spread out</h5>
</div>
<div id="the-red-line-in-this-plot-seems-to-have-a-slightly-positive-slope-and-the-points-seem-to-be-fanning-out" class="section level5">
<h5>The red line in this plot seems to have a slightly positive slope and the points seem to be fanning out</h5>
</div>
<div id="there-is-a-possibility-that-the-assumption-of-homoscedasticity-is-not-met" class="section level5">
<h5>There is a possibility that the assumption of homoscedasticity is not met</h5>
<pre class="r"><code>plot(assumptions,3)</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
</div>
<div id="formally-test-for-homoscedasticity-using-the-breush-pagan-bp-test" class="section level3">
<h3>Formally test for homoscedasticity using the Breush-Pagan (bp) Test</h3>
<div id="since-the-p-value-is-p-value-is-less-than-.05-we-reject-the-null-hypothesis-that-there-is-no-heteroscedasticity." class="section level5">
<h5>Since the p-value is p-value is less than .05, we reject the null hypothesis that there is no heteroscedasticity.</h5>
</div>
<div id="this-means-we-have-failed-the-assumption-of-homoscedasticity" class="section level5">
<h5>This means we have failed the assumption of homoscedasticity</h5>
<pre class="r"><code>bptest&lt;-lm(salary ~ yrs.since.phd * yrs.service, data=Salaries)
bptest(bptest) </code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  bptest
## BP = 44.85, df = 3, p-value = 9.957e-10</code></pre>
</div>
</div>
<div id="standard-errors-robust-to-violations-of-homoskedasticity" class="section level3">
<h3>Standard Errors robust to violations of homoskedasticity</h3>
<pre class="r"><code>coeftest(fit1, vcov=vcovHC(fit1))[,1:2]</code></pre>
<pre><code>##                              Estimate Std. Error
## (Intercept)               70155.26272 2866.21795
## yrs.since.phd              2194.28869  316.65269
## yrs.service                1692.44646  424.95227
## yrs.since.phd:yrs.service   -64.61694   11.01044</code></pre>
<div id="the-proportion-of-variation-in-the-response-variable-salary-explained-by-the-overall-model-all-predictors-years-since-phd-and-years-in-service" class="section level5">
<h5>The proportion of variation in the response variable (salary) explained by the overall model (all predictors: years since PhD and years in service)</h5>
<pre class="r"><code>(sum((Salaries$salary-mean(Salaries$salary))^2)-sum(fit1$residuals^2))/sum((Salaries$salary-mean(Salaries$salary))^2)</code></pre>
<pre><code>## [1] 0.3176664</code></pre>
</div>
</div>
<div id="bootstrapping" class="section level3">
<h3>Bootstrapping</h3>
<pre class="r"><code>samp_distn&lt;-replicate(5000, {
  boot_dat &lt;- sample_frac(Salaries, replace=T) #take bootstrap sample of rows
  fit &lt;- lm(salary ~ yrs.since.phd * yrs.service, data=boot_dat) #fit model on bootstrap sample
  coef(fit) #save coefs
})</code></pre>
<div id="estimated-ses-the-bootstrap-ses-are-lower-than-the-robust-ses-and-original-ses" class="section level5">
<h5>Estimated SEs: the bootstrap SEs are lower than the robust SEs and original SEs</h5>
<pre class="r"><code>samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) yrs.since.phd yrs.service yrs.since.phd:yrs.service
## 1    2769.631       301.183    413.5226                  10.54624</code></pre>
</div>
</div>
<div id="logistic-regression-model" class="section level3">
<h3>Logistic Regression Model</h3>
<div id="make-a-new-column-and-convert-the-sex-variable-into-a-binary-male-1-female-2" class="section level5">
<h5>Make a new column and convert the sex variable into a binary, Male = 1, Female = 2</h5>
<pre class="r"><code>Salaries$sex_b &lt;- ifelse(Salaries$sex == &#39;Male&#39;, 1, 0)</code></pre>
<pre class="r"><code>library(plotROC)
fit2&lt;-glm(sex_b ~ salary + rank,data=Salaries, family = binomial(link = &quot;logit&quot;))
coeftest(fit2)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                  Estimate  Std. Error z value Pr(&gt;|z|)
## (Intercept)    6.4430e-01  7.8154e-01  0.8244   0.4097
## salary         1.2212e-05  8.8293e-06  1.3831   0.1666
## rankAssocProf -9.4692e-02  4.8910e-01 -0.1936   0.8465
## rankProf       4.7738e-01  5.3669e-01  0.8895   0.3737</code></pre>
<pre class="r"><code>exp(coef(fit2))</code></pre>
<pre><code>##   (Intercept)        salary rankAssocProf      rankProf 
##     1.9046558     1.0000122     0.9096534     1.6118483</code></pre>
</div>
<div id="from-the-p-values-we-can-deduce-that-there-is-no-significant-difference-amongst-these-explanatory-variables-when-controlling-for-the-others." class="section level5">
<h5>From the p-values, we can deduce that there is no significant difference amongst these explanatory variables when controlling for the others.</h5>
</div>
<div id="odds-each-variable-has-positive-odds-for-being-male.-this-could-be-due-to-the-prominence-of-male-test-subjects-in-this-dataset.-intercept-controlling-for-salary-the-odds-of-an-assistant-professor-is-higher-than-other-than-the-other-ranks.-controlling-for-salary-professor-has-higher-odds-of-being-male-than-associate.-controlling-for-rank-salary-has-a-positive-impact-on-being-male." class="section level5">
<h5>Odds: Each variable has positive odds for being male. This could be due to the prominence of male test subjects in this dataset. Intercept: Controlling for salary, the odds of an assistant professor is higher than other than the other ranks. Controlling for salary, Professor has higher odds of being male than associate. Controlling for rank, salary has a positive impact on being male.</h5>
</div>
</div>
<div id="predicted-logit-log-odds-with-specific-target" class="section level3">
<h3>Predicted logit (log-odds) with specific target</h3>
<pre class="r"><code>professor1 &lt;- data.frame(salary = 100000, rank = &#39;Prof&#39;)

predict(fit2, newdata=professor1, type= &quot;link&quot;)</code></pre>
<pre><code>##        1 
## 2.342895</code></pre>
</div>
<div id="predicted-probability-of-professor1-being-a-male" class="section level3">
<h3>Predicted probability of professor1 being a male</h3>
<pre class="r"><code>predict(fit2, newdata=professor1, type = &quot;response&quot;)</code></pre>
<pre><code>##         1 
## 0.9123678</code></pre>
</div>
<div id="creating-confusion-matrix-of-fit2" class="section level3">
<h3>Creating Confusion Matrix of fit2</h3>
<pre class="r"><code>prob&lt;-predict(fit2,type=&quot;response&quot;) #get predictions for every student in the dataset
pred&lt;-ifelse(prob&gt;.5,1,0)
table(prediction=pred, truth=Salaries$sex_b) %&gt;% addmargins</code></pre>
<pre><code>##           truth
## prediction   0   1 Sum
##        1    39 358 397
##        Sum  39 358 397</code></pre>
<pre class="r"><code>mean(Salaries$sex_b==pred) # Accuracy</code></pre>
<pre><code>## [1] 0.9017632</code></pre>
<pre class="r"><code>358/358 #TPR</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>0/39 #TNR</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>358/397 #PPV</code></pre>
<pre><code>## [1] 0.9017632</code></pre>
<div id="the-confusion-matrix-predicts-male-when-it-is-actually-female.-accuracy-is-0.902-tpr-is-358358-1-tnr-is-039-0-ppv-is-358397-0.902.-the-auc-is-0.6449291." class="section level5">
<h5>The confusion matrix predicts male when it is actually female. Accuracy is 0.902 TPR is 358/358 = 1, TNR is 0/39 = 0, PPV is 358/397 = 0.902. The AUC is 0.6449291.</h5>
</div>
</div>
<div id="roc-plots.-auc-0.645" class="section level3">
<h3>ROC plots. AUC = 0.645</h3>
<pre class="r"><code>Salaries$prob&lt;-predict(fit2,type=&quot;response&quot;) 

sens&lt;-function(p,data=Salaries, y=sex_b) mean(Salaries[Salaries$sex_b==1,]$prob&gt;p) 
spec&lt;-function(p,data=Salaries, y=sex_b) mean(Salaries[Salaries$sex_b==0,]$prob&lt;p) 
sensitivity&lt;-sapply(seq(0,1,.01),sens,Salaries) #TPR
specificity&lt;-sapply(seq(0,1,.01),spec,Salaries) #TNR
ROC1&lt;-data.frame(sensitivity,specificity,cutoff=seq(0,1,.01))

ROC1$TPR&lt;-sensitivity
ROC1$FPR&lt;-1-specificity

ROCplot&lt;-ggplot(Salaries)+geom_roc(aes(d=sex_b,m=prob), n.cuts=0)+ geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2)
ROC1%&gt;%ggplot(aes(FPR,TPR))+geom_path(size=1.5)+geom_segment(aes(x=0,y=0,xend=1,yend=1)) + scale_x_continuous(limits = c(0,1))</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code>ROCplot</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.6449291</code></pre>
</div>
<div id="logistic-model-with-all-other-explanatory-variables" class="section level3">
<h3>Logistic Model with all other explanatory variables</h3>
<pre class="r"><code>fit3&lt;-glm(sex_b ~ discipline + yrs.since.phd + yrs.service,data=Salaries, family = binomial(link = &quot;logit&quot;))
coeftest(fit3)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##               Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept)   1.292535   0.401655  3.2180 0.001291 **
## disciplineB   0.220338   0.350788  0.6281 0.529924   
## yrs.since.phd 0.012193   0.032657  0.3734 0.708884   
## yrs.service   0.038649   0.034653  1.1153 0.264717   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(fit3))</code></pre>
<pre><code>##   (Intercept)   disciplineB yrs.since.phd   yrs.service 
##      3.642006      1.246498      1.012267      1.039405</code></pre>
<div id="intercept-controlling-for-years-since-phd-and-years-of-service-and-discipline-b-discipline-a-has-a-signicant-effect-on-being-male." class="section level5">
<h5>Intercept: Controlling for years since PhD and years of service, and discipline B, discipline A has a signicant effect on being male.</h5>
</div>
</div>
<div id="creating-confusion-matrix-of-fit3." class="section level3">
<h3>Creating Confusion Matrix of fit3.</h3>
<pre class="r"><code>prob&lt;-predict(fit3,type=&quot;response&quot;) #get predictions for every student in the dataset
pred&lt;-ifelse(prob&gt;.5,1,0)
table(prediction=pred, truth=Salaries$sex_b) %&gt;% addmargins</code></pre>
<pre><code>##           truth
## prediction   0   1 Sum
##        1    39 358 397
##        Sum  39 358 397</code></pre>
<pre class="r"><code>mean(Salaries$sex_b==pred) # Accuracy</code></pre>
<pre><code>## [1] 0.9017632</code></pre>
<pre class="r"><code>358/358 #TPR</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>0/39  #TNR</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>358/397 #PPV</code></pre>
<pre><code>## [1] 0.9017632</code></pre>
<pre class="r"><code>Salaries$prob&lt;-predict(fit3,type=&quot;response&quot;) 

sens&lt;-function(p,data=Salaries, y=sex_b) mean(Salaries[Salaries$sex_b==1,]$prob&gt;p) 
spec&lt;-function(p,data=Salaries, y=sex_b) mean(Salaries[Salaries$sex_b==0,]$prob&lt;p) 
sensitivity&lt;-sapply(seq(0,1,.01),sens,Salaries) #TPR
specificity&lt;-sapply(seq(0,1,.01),spec,Salaries) #TNR</code></pre>
</div>
<div id="roc-plots.-auc-is-0.6484386" class="section level3">
<h3>ROC plots. AUC is 0.6484386</h3>
<pre class="r"><code>ROC1&lt;-data.frame(sensitivity,specificity,cutoff=seq(0,1,.01))

ROC1$TPR&lt;-sensitivity
ROC1$FPR&lt;-1-specificity


ROCplot&lt;-ggplot(Salaries)+geom_roc(aes(d=sex_b,m=prob), n.cuts=0)+ geom_segment(aes(x=0,xend=1,y=0,yend=1),lty=2)
ROC1%&gt;%ggplot(aes(FPR,TPR))+geom_path(size=1.5)+geom_segment(aes(x=0,y=0,xend=1,yend=1)) + scale_x_continuous(limits = c(0,1))</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<pre class="r"><code>ROCplot</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-28-2.png" width="672" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.6484386</code></pre>
</div>
<div id="perform-10-fold-cross-validation" class="section level3">
<h3>Perform 10-fold cross-validation</h3>
<pre class="r"><code>class_diag &lt;- function(probs,truth){
#CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
acc=sum(diag(tab))/sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
f1=2*(sens*ppv)/(sens+ppv)
if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
#CALCULATE EXACT AUC
ord&lt;-order(probs, decreasing=TRUE)
probs &lt;- probs[ord]; truth &lt;- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
n &lt;- length(TPR)
auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,f1,auc)
}

set.seed(1234)
k=10 #choose number of folds
data&lt;-Salaries[sample(nrow(Salaries)),] #randomly order rows
folds&lt;-cut(seq(1:nrow(Salaries)),breaks=k,labels=F) #create folds
diags&lt;-NULL
for(i in 1:k){
## Create training and test sets
train&lt;-data[folds!=i,]
test&lt;-data[folds==i,]
truth&lt;-test$sex_b ## Truth labels for fold i
## Train model on training set (all but fold i)
fit3&lt;-glm(sex_b ~ discipline + yrs.since.phd + yrs.service,data=train,family=&quot;binomial&quot;)
## Test model on test set (fold i)
probs&lt;-predict(fit3,newdata = test,type=&quot;response&quot;)
## Get diagnostics for fold i
diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean) #average diagnostics across all k folds</code></pre>
<pre><code>##         acc sens spec       ppv        f1       auc
## 1 0.9016667    1    0 0.9016667 0.9478306 0.6650352</code></pre>
<div id="accuracy0.902-sensitivity0-specificity0-precision0.902-and-auc0.665.-the-auc-is-really-low-which-means-our-model-is-performing-badly." class="section level5">
<h5>Accuracy=0.902, Sensitivity=0, Specificity=0, Precision=0.902, and AUC=0.665. The AUC is really low which means our model is performing badly.</h5>
</div>
</div>
<div id="perform-lasso" class="section level3">
<h3>Perform LASSO</h3>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Loaded glmnet 4.0-2</code></pre>
<pre class="r"><code>y&lt;-as.matrix(Salaries$sex_b) #grab response
x&lt;-model.matrix(sex_b ~ discipline + yrs.since.phd + yrs.service, data=Salaries)[,-1] #grab predictors

x&lt;-scale(x) #standardize

cv &lt;- cv.glmnet(x,y, family=&quot;binomial&quot;) 
{plot(cv$glmnet.fit, &quot;lambda&quot;, label=TRUE); abline(v = log(cv$lambda.1se));}</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<pre class="r"><code>lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 4 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     s0
## (Intercept)   2.216971
## disciplineB   0.000000
## yrs.since.phd .       
## yrs.service   .</code></pre>
<div id="discipline-is-the-most-predictive-variable-so-it-is-retained." class="section level5">
<h5>Discipline is the most predictive variable so it is retained.</h5>
</div>
</div>
<div id="cross-validate-the-lasso-model" class="section level3">
<h3>Cross-Validate the Lasso Model</h3>
<pre class="r"><code>set.seed(1234)
k=10
data &lt;- Salaries %&gt;% sample_frac #put rows of dataset in random order
folds &lt;- ntile(1:nrow(data),n=10) #create fold labels
diags&lt;-NULL
for(i in 1:k){
train &lt;- data[folds!=i,] #create training set (all but fold i)
test &lt;- data[folds==i,] #create test set (just fold i)
truth &lt;- test$sex_b #save truth labels from fold i
fit &lt;- glm(sex_b~discipline,
data=train, family=&quot;binomial&quot;)
probs &lt;- predict(fit, newdata=test, type=&quot;response&quot;)
diags&lt;-rbind(diags,class_diag(probs,truth))
}
diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>##         acc sens spec       ppv        f1      auc
## 1 0.9015385    1    0 0.9015385 0.9477519 0.387913</code></pre>
<div id="the-auc-became-lower..-there-was-no-evidence-for-overfitting-so-the-lasso-model-caused-the-auc-to-lower-even-further.-i-believe-the-variables-in-the-dataset-did-not-display-an-effective-pattern-for-predicting-sex.-the-models-underperformance-may-be-due-to-the-data-itself-being-unpredictable." class="section level5">
<h5>The AUC became lower.. There was no evidence for overfitting so the LASSO model caused the AUC to lower even further. I believe the variables in the dataset did not display an effective pattern for predicting sex. The model’s underperformance may be due to the data itself being unpredictable.</h5>
</div>
</div>
</div>
